{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "dda4fc99-2f89-e2aa-aeb4-f702cc51afaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "from keras import metrics\n",
    "from sklearn import metrics as me\n",
    "print('import done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "ea5ca33e-fdfc-e060-aade-bcda984694d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     v1                                                 v2\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('spam.csv', encoding='latin-1', usecols=['v1', 'v2'])\n",
    "print(df.head())\n",
    "\n",
    "tags = df.v1\n",
    "texts = df.v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "a6bf4566-ed56-7d41-f46c-e9b92c788bcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0]\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 3. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]]\n",
      "(5572,) (5572, 1000)\n"
     ]
    }
   ],
   "source": [
    "num_max = 1000\n",
    "# preprocess\n",
    "le = LabelEncoder()\n",
    "tags = le.fit_transform(tags)\n",
    "tok = Tokenizer(num_words=num_max)\n",
    "tok.fit_on_texts(texts)\n",
    "mat_texts = tok.texts_to_matrix(texts,mode='count')\n",
    "print(tags[:5])\n",
    "print(mat_texts[:5])\n",
    "print(tags.shape,mat_texts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "37a8025b-eeac-f70f-1768-a7d66dc7c210"
   },
   "outputs": [],
   "source": [
    "# try a simple model first\n",
    "\n",
    "def get_simple_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(num_max,)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc',metrics.binary_accuracy])\n",
    "    print('compile done')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "4f3ff2b6-ed23-076a-141d-25adbc4f8592"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 469, 841, 751, 657, 64, 8, 89, 121, 349, 147, 67, 58, 144]\n",
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0  50 469 841 751\n",
      " 657  64   8  89 121 349 147  67  58 144]\n",
      "(5572, 100)\n"
     ]
    }
   ],
   "source": [
    "# for cnn preproces\n",
    "max_len = 100\n",
    "cnn_texts_seq = tok.texts_to_sequences(texts)\n",
    "print(cnn_texts_seq[0])\n",
    "cnn_texts_mat = sequence.pad_sequences(cnn_texts_seq,maxlen=max_len)\n",
    "print(cnn_texts_mat[0])\n",
    "print(cnn_texts_mat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "e06c4200-569d-d9b0-b36c-8a8534157f01"
   },
   "outputs": [],
   "source": [
    "def get_cnn_model_v1(max_len=100):   \n",
    "    model = Sequential()\n",
    "    # we start off with an efficient embedding layer which maps\n",
    "    # our vocab indices into embedding_dims dimensions\n",
    "    # 1000 is num_max\n",
    "    model.add(Embedding(1000,\n",
    "                        20,\n",
    "                        input_length=max_len))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(64,\n",
    "                     3,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc', metrics.binary_accuracy])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "6578767b-e047-1b6d-c128-3e2e4e3e2414"
   },
   "outputs": [],
   "source": [
    "def get_cnn_model_v2(max_len=100): # added embed   \n",
    "    model = Sequential()\n",
    "    # we start off with an efficient embedding layer which maps\n",
    "    # our vocab indices into embedding_dims dimensions\n",
    "    # 1000 is num_max\n",
    "    model.add(Embedding(1000,\n",
    "                        50, #!!!!!!!!!!!!!!!!!!!!!!!\n",
    "                        input_length=max_len))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(64,\n",
    "                     3,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc',metrics.binary_accuracy])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "d1a65f27-c61e-13db-49ff-7cf816b70fa1"
   },
   "outputs": [],
   "source": [
    "def get_cnn_model_v3(max_len=100):    # added filter\n",
    "    model = Sequential()\n",
    "    # we start off with an efficient embedding layer which maps\n",
    "    # our vocab indices into embedding_dims dimensions\n",
    "    # 1000 is num_max\n",
    "    model.add(Embedding(1000,\n",
    "                        20,\n",
    "                        input_length=max_len))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv1D(256, #!!!!!!!!!!!!!!!!!!!\n",
    "                     3,\n",
    "                     padding='valid',\n",
    "                     activation='relu',\n",
    "                     strides=1))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(256))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# prepare the dataset\n",
    "def get_data(train, test):\n",
    "    # generate dataset\n",
    "    X, y = train, test\n",
    "    trainX, testX, trainy, testy = train_test_split(X, y, test_size=0.3, random_state=43)\n",
    "    return trainX, trainy, testX, testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def get_metrics(test, pred):\n",
    "    print(\"Metrics Measures\")\n",
    "    # accuracy: (tp + tn) / (p + n)\n",
    "    accuracy = accuracy_score(test, pred)\n",
    "    print('Accuracy: %f' % accuracy)\n",
    "    # precision tp / (tp + fp)\n",
    "    precision = precision_score(test, pred)\n",
    "    print('Precision: %f' % precision)\n",
    "    # recall: tp / (tp + fn)\n",
    "    recall = recall_score(test, pred)\n",
    "    print('Recall: %f' % recall)\n",
    "    # f1: 2 tp / (2 tp + fp + fn)\n",
    "    f1 = f1_score(test, pred)\n",
    "    print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               512512    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 644,097\n",
      "Trainable params: 644,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "compile done\n",
      "WARNING:tensorflow:From <ipython-input-11-fc3c0d22d8df>:10: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "Metrics Measures\n",
      "Accuracy: 0.981459\n",
      "Precision: 0.976303\n",
      "Recall: 0.887931\n",
      "F1 score: 0.930023\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "def check_model(model, x, y):\n",
    "    callback = ModelCheckpoint(filepath='best_model.hdf5', monitor='loss', mode='min')\n",
    "    model.fit(x, y, batch_size=32, epochs=20, verbose=0, callbacks=callback)\n",
    "    \n",
    "\n",
    "trainX, trainy, testX, testy = get_data(mat_texts, tags)\n",
    "m = get_simple_model()\n",
    "check_model(m, trainX, trainy)\n",
    "pred = m.predict_classes(testX)\n",
    "pred = pred[:, 0]\n",
    "\n",
    "get_metrics(testy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 20)           20000     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100, 20)           0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 98, 64)            3904      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 40,801\n",
      "Trainable params: 40,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Metrics Measures\n",
      "Accuracy: 0.977871\n",
      "Precision: 0.941176\n",
      "Recall: 0.896552\n",
      "F1 score: 0.918322\n"
     ]
    }
   ],
   "source": [
    "#CNN 1\n",
    "trainX, trainy, testX, testy = get_data(cnn_texts_mat, tags)\n",
    "m = get_cnn_model_v1()\n",
    "check_model(m, trainX, trainy)\n",
    "pred = m.predict_classes(testX)\n",
    "pred = pred[:, 0]\n",
    "\n",
    "get_metrics(testy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 50)           50000     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100, 50)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 98, 64)            9664      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 76,561\n",
      "Trainable params: 76,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Metrics Measures\n",
      "Accuracy: 0.982057\n",
      "Precision: 0.959091\n",
      "Recall: 0.909483\n",
      "F1 score: 0.933628\n"
     ]
    }
   ],
   "source": [
    "#CNN 2\n",
    "trainX, trainy, testX, testy = get_data(cnn_texts_mat, tags)\n",
    "m = get_cnn_model_v2()\n",
    "check_model(m, trainX, trainy)\n",
    "pred = m.predict_classes(testX)\n",
    "pred = pred[:, 0]\n",
    "\n",
    "get_metrics(testy, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 100, 20)           20000     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 100, 20)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 98, 256)           15616     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 101,665\n",
      "Trainable params: 101,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Metrics Measures\n",
      "Accuracy: 0.980263\n",
      "Precision: 0.954338\n",
      "Recall: 0.900862\n",
      "F1 score: 0.926829\n"
     ]
    }
   ],
   "source": [
    "#CNN 3\n",
    "trainX, trainy, testX, testy = get_data(cnn_texts_mat, tags)\n",
    "m = get_cnn_model_v3()\n",
    "check_model(m, trainX, trainy)\n",
    "pred = m.predict_classes(testX)\n",
    "pred = pred[:, 0]\n",
    "\n",
    "get_metrics(testy, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With more finetuning, i would get better f1-scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 4,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
